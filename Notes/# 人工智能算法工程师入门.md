# 人工智能算法工程师入门

## 5.机器学习

### 5.1机器学习理论及常见任务

人工智能-**机器学习**-深度算法

特征：可供识别的标志。

特征的重要程度不一样

- 相关特征
- 无关特征

常见数据集：

- Iris
- Adult

特征编码：将每一个特征转化为可计算的**数字**

- 序号编码：本身有个内在的顺序关系，如学历
- 独热编码：一位有效编码

特征选择：

- 过滤式：预先选择，再训练学习器。选择与后续的训练**无关**
- 包裹式：以最终学习器的性能作为标准选择特征
- 嵌入式：特征选择与训练融为一体
- 深度学习：自动化选择

机器学习问题

- 有监督学习：有标记，学习输入与输出之间的关系
- 无监督学习：无标记，自动发现规律或结构
- 半监督/弱监督：部分数据有标签/标签不完整
- 强化学习：与环境交互中学习，达成最大回报或特定目标。有奖励信号，没有监督

有监督学习

- 分类：标签为**离散**类别数值
- 回归：标签为**连续**数值

无监督学习模型

- 降维：特征映射。降低复杂度，可以可视化
- 聚类：分类问题
- 生成：估计概率密度函数

### 5.2 评估目标与优化目标

样本集

- 训练集：学习模型本身的参数
- 验证集：优化模型训练中的超参数
- 测试集：测试精度

N折交叉验证技术：充分训练和测试

评测指标：衡量算法优劣

正负样本划分（分类是啥就是啥，标签与分类一样就是真，否则就是假）

- TP
- FP
- FN
- TN

分类任务的常见评估指标

- 准确率 *？？定义是不是不对？？*
- 正样本精度
- 正样本召回率
- PR曲线 ：面积越大越好
- F1 score
- ROC曲线：真阳率和假阳率
- AUC
- 混淆矩阵

回归任务常见的指标

- IoU
- PSNR

模型优化

- 优化目标：loss function（代理损失函数 只取样本上的损失函数值）
- 欠拟合
- 过拟合：模型过大，数据过少
- 适当拟合

分类任务的优化目标

- 0-1损失
- 交叉熵损失
- softmax loss：交叉熵的特例

回归任务的优化目标

- L1 loss
- L2 loss
- Smooth L1 loss：将L1和L2结合

### 5.3 机器学习案例实战

如何区别樱桃的猕猴桃？建模：

- 将重量和颜色作为特征，以此画出平面直角坐标系
- 将樱桃和猕猴桃抽象成平面上的点
- 这些点可以用一条直线进行区分，在左上方为樱桃，后下方为猕猴桃-线性分类器
- 建模：转化为学习一个直线方程（ax+by+c）的三个参数

逻辑回归模型：二分类算法

- 属于正样本的概率大于属于负样本的概率，就分为正样本

## 6.神经网络

### 6.1 单层神经网络

MP模型：能够进行逻辑运算

输入-权重-求和-映射

单层感知器

与MP的不同点：

- 输入是连续的
- 激活函数不一定是阈值函数
- 权重不是固定的

感知器权重**参数更新**方法：梯度下降算法

学习率：LR，用于控制参数更新的步长

线性分类问题

- 单层感知器作为线性分类器被广泛应用

### 6.2 多层神经网络

多层感知器

- 单层感知器无法解决异或问题
- 多层感知器MLP：引入隐藏层-前馈神经网络
- **非线性**分界面，网络层必须加入非线性激活函数

反向传播算法：

损失函数从后向前

### 6.3 序列神经网络

序列预测问题：

- 分类 Sequence-to-vector
- 同步序列预测 Sequence-to-sequence
- 异步序列预测 Encoder-Decoder
- 序列生成 vector-to-sequence

循环神经网络RNN：

带有自反馈的神经网络，处理任意长度的时序数据

双向RNN模型：上下文信息更完整

RNN参数学习：

- 随时间反向传播算法BPFT
- 梯度问题：连乘的形式，由于某一项很小或很大出现梯度爆炸或消失
  - **长距离依赖问题** 

长短时记忆网络LSTM：

解决RNN训练过程中出现的长距离依赖问题

- 遗忘门
- 输入门
- 输出门

## 7.卷积神经网络

### 7.1 卷积神经网络基础


## 图神经网络

### introduction

图：

- 点
  - 对点进行分类
- 边
  - 预测属性
- 图
  - 对图分类

- 图变成图
- 文字变成图
- 分子图
- 社交网络图
- 引用图
- 知识图

图上的属性：点、边、全局信息、连接性

点：向量
边：向量
全局信息：向量
连接性：第i项表示第i条边连接哪两个顶点

### 图神经网络GNN

- 对图上属性的一种可优化的**变换**
- 会改变点、边、全局信息，不会改变连接性

最简单的层：

对U V E 分别有一个MLP，三个MLP构成一个GNN的层

如何对顶点做分类：

对最后输出的图再加入一层全连接层在家softmax可得到输出。若没有点的向量，做一个汇聚层，将边的向量合成为顶点的向量

改进：

信息传递：

对顶点的向量进行更新：

- 将自己的向量和邻接的向量合成为新的向量，然后经过变换得到新的向量
- 顶点和边能做信息交换
