# 人工智能入门

了解基本概念，学习编程语言（python），核心是**机器学习**和**深度学习**，学习工具和框架，暂时不管**数学**推导



人工智能的应用

- 计算机视觉
- 自然语言处理
- 语音识别



图灵测试/专家系统/机器学习/深度学习



## 机器学习



训练 -> 推理

训练：数据 - 算法 ->  模型



- 监督式机器学习：标签和特征，预测特征上的标签
  - 分类预测
  - 回归预测
- 无监督机器学习：未标记数据
- 强化学习



## 深度学习

利用多层神经网络 从数据中进行学习

- 找出数据中的模式
- 机器学习：特征抽取和分类回归是人力的
- 深度学习：两者也是学习的一部分，端到端模式，易于优化



## Python环境

miniconda + pycharm













# 深度学习

深度学习是机器学习的一部分，数据预处理和特征提取是最核心的，可以用于文本处理和计算机视觉

机器学习常规套路：

1. 收集数据并给定标签
2. 训练一个**分类器**
3. 测试评估



## 神经网络基础



### 线性函数/得分函数

从输入到输出的映射，矩阵运算

`f(x,W,b) = Wx + b`

- **特征**矩阵x
- 每个特征对应一个不同的**权重参数**矩阵w，决定性
- 函数有一个**偏置参数**矩阵b，各自类别各自微调
- 输出为每个**类别的得分**，得到结果矩阵



神经网络要做的事情：什么样的w更适合？->改进w参数





### 损失函数

- 衡量得分函数的结果好坏

- 损失函数得越低越好
- 数据损失+正则化惩罚项
- 回归任务由得分值得到损失，分类任务由概率值得到损失



损失函数的改进

- 要加个Δ（通常=1），作为**容忍程度**，代表正确结果和错误结果之间的得分要有一定的差距

- 正则化惩罚项：跟数据无关，只考虑权重参数w，**过拟合**的模型是没用的



### softmax分类器

将**得分值**转化为一个**概率值**

- 放大差异：e的x次幂
- 归一化：某个数比各数之和 = 概率值
- 用对数函数求损失：概率值越接近1，损失越小（-log）



-->**前向传播**：数据输入后得到一个损失，**对x做了什么**

---

### 反向传播？

优化w：**对w做了什么**

梯度是什么？高数中的概念？

梯度下降？

链式法则：梯度逐层一步一步的计算



### 神经网络的整体架构

层次结构，一层一层的变化输入的数据

- 输入层
- 隐藏层1，2....
- 输出层

神经元

- 输入层：输入的数据的特征个数
- 隐藏层：将原始输入的特征进行变化，得到一组新的特征，特征个数可能会变化
- 个数多少？

全连接

- 权重参数矩阵将输入数据的原始特征转化成一组新的特征

非线性

- 矩阵计算之后要利用非线性函数进行映射



正则化的作用

- 惩罚力度越小，越符合训练集->**过拟合**
- 力度越大，形状规则 



### 激活函数

非线性变换

- sigmod函数->梯度消失
- relu函数



### 数据预处理

- 数据标准化
- 参数初始化



### drop-out

- 解决过拟合风险：让神经网络弱一点
- 训练的过程中：随机杀死一些神经元









## 卷积神经网络

cnn再计算机视觉的应用

- 检测任务
- 分类和检索
- 超分辨重构
- 无人驾驶
- 人脸识别



卷积网络的神经网络与传统的区别

- 直接特征提取，三维的



结构

- 输入层
- 卷积层
- 池化层
- 全连接层



### 卷积

卷积的作用：

- 分成不同的区域
- 对每个区域计算特征值
- ---->特征图
- 多个特征图可以堆叠在一起
- 卷积可以进行多次



卷积的参数：

- 滑动窗口步长
- 卷积核的尺寸
- 边缘填充
  - 外边添加一圈0
  - 解决边界点对结果的影响偏小的问题
- 卷积核个数



卷积参数共享，参数很少，好训练



### 池化层

压缩，下采样，选择重要的留下来，不重要的丢掉

- 选择区域
- 每个区域筛选一个值



### 卷积神经网络架构

- 经过一次卷积计算，加一次非线性变化

- 几组卷积之后进行一次池化

- 将三维转化成一个向量
- 最后经过全连接层得到结果



常见架构：

- Alexnet

- vgg

  - 网络层多

  - 卷积核小

- resnet

  - 上述架构：并非层数越多效果越好
  - 再层数叠加的时候加上筛选机制，对结果负面影响的层就不带他玩了



### 感受野

由前面的多少数据生成的



## 递归神经网络

rnn

### 网络架构





